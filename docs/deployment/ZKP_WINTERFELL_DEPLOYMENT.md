# QUY TR√åNH TRI·ªÇN KHAI ZK-ROLLUP V·ªöI WINTERFELL
## Track B: Zero Knowledge Proofs cho Blockchain Li√™n Ng√¢n H√†ng

**D·ª± √°n:** NT219 - M·∫≠t m√£ h·ªçc  
**T√†i li·ªáu tham kh·∫£o:** [NT219_BaoCaoTienDo-2.pdf](file:///home/quy/project/NT219_Project/docs/reference/NT219_BaoCaoTienDo-2.pdf)

---

## M·ª•c l·ª•c

1. [T·ªïng quan Track B](#i-t·ªïng-quan-track-b)
2. [Chu·∫©n b·ªã m√¥i tr∆∞·ªùng Rust](#ii-chu·∫©n-b·ªã-m√¥i-tr∆∞·ªùng-rust)
3. [T·∫°o Prover Module](#iii-t·∫°o-prover-module)
4. [Implement STARK Prover v·ªõi Winterfell](#iv-implement-stark-prover-v·ªõi-winterfell)
5. [T·∫°o Verifier Smart Contract](#v-t·∫°o-verifier-smart-contract)
6. [T√≠ch h·ª£p Batching System](#vi-t√≠ch-h·ª£p-batching-system)
7. [Testing & Benchmark](#vii-testing--benchmark)
8. [T√≠ch h·ª£p v·ªõi Track A (PQC)](#viii-t√≠ch-h·ª£p-v·ªõi-track-a-pqc)

---

## I. T·ªîNG QUAN TRACK B

### 1.1. Workflow theo b√°o c√°o

Theo m·ª•c 5.2 c·ªßa b√°o c√°o ti·∫øn ƒë·ªô:

```
[Track A: PQC Transactions]
    ‚Üì
[1. BATCHING]
    ‚Üí Gom nhi·ªÅu giao d·ªãch PQC th√†nh m·ªôt batch
    ‚Üì
[2. PROVER (Off-chain - Winterfell)]
    ‚Üí Sinh zk-STARK proof cho to√†n b·ªô batch
    ‚Üí Kh√¥ng ti·∫øt l·ªô chi ti·∫øt giao d·ªãch
    ‚Üì
[3. VERIFIER CONTRACT (On-chain)]
    ‚Üí Nh·∫≠n v√† x√°c minh proof
    ‚Üí C·∫≠p nh·∫≠t state root m·ªõi tr√™n ledger
    ‚Üì
[Track C: Consensus & Ledger Update]
```

### 1.2. L·ª£i √≠ch c·ªßa ZK-Rollup

**Privacy Enhancement:**
- Che gi·∫•u s·ªë ti·ªÅn giao d·ªãch (amount)
- Che gi·∫•u ƒë·ªãa ch·ªâ ng∆∞·ªùi g·ª≠i/nh·∫≠n
- Ch·ªâ c√¥ng khai state root

**Scalability:**
- Batch nhi·ªÅu transactions ‚Üí 1 proof
- Gi·∫£m on-chain data
- TƒÉng throughput (TPS)

**Cost Reduction:**
- Verify 1 proof thay v√¨ N signatures
- Gi·∫£m gas cost

---

## II. CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG RUST

### 2.1. C√†i ƒë·∫∑t Rust

```bash
# C√†i ƒë·∫∑t Rust toolchain
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Reload environment
source $HOME/.cargo/env

# Ki·ªÉm tra
rustc --version    # rustc 1.75.0+
cargo --version    # cargo 1.75.0+
```

### 2.2. C√†i ƒë·∫∑t c√°c dependencies c·∫ßn thi·∫øt

```bash
# Build tools
sudo apt install -y build-essential pkg-config libssl-dev

# Ki·ªÉm tra
gcc --version
```

### 2.3. T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c Prover

```bash
cd ~/project/NT219_Project

# T·∫°o folder prover
mkdir -p prover
cd prover

# Initialize Rust project
cargo init --name zkp-prover

# Ki·ªÉm tra structure
tree -L 2
```

**Expected structure:**
```
prover/
‚îú‚îÄ‚îÄ Cargo.toml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ main.rs
‚îî‚îÄ‚îÄ target/
```

---

## III. T·∫†O PROVER MODULE

### 3.1. C·∫•u h√¨nh Cargo.toml

```bash
cat > Cargo.toml << 'EOF'
[package]
name = "zkp-prover"
version = "0.1.0"
edition = "2021"

[dependencies]
# Winterfell - STARK prover library
winterfell = "0.9"

# Math operations
crypto-bigint = "0.5"
hex = "0.4"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Hashing
sha3 = "0.10"

# Web server for API
actix-web = "4"
actix-rt = "2"

# Logging
env_logger = "0.11"
log = "0.4"

# Async
tokio = { version = "1", features = ["full"] }

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
EOF
```

### 3.2. T·∫°o c·∫•u tr√∫c module

```bash
cd ~/project/NT219_Project/prover

# T·∫°o c√°c modules
mkdir -p src/{batching,stark,verifier,api}

# T·∫°o lib.rs
cat > src/lib.rs << 'EOF'
pub mod batching;
pub mod stark;
pub mod verifier;
pub mod api;

pub use batching::TransactionBatch;
pub use stark::{STARKProver, STARKProof};
pub use verifier::ProofVerifier;
EOF
```

---

## IV. IMPLEMENT STARK PROVER V·ªöI WINTERFELL

### 4.1. Define Transaction Structure

```bash
cat > src/batching/mod.rs << 'EOF'
use serde::{Deserialize, Serialize};

/// PQC Transaction t·ª´ Track A
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PQCTransaction {
    pub from: String,           // Bank address
    pub to: String,             // Recipient address
    pub amount: u64,            // Amount in wei
    pub timestamp: u64,
    pub pqc_signature: String,  // Dilithium3 signature
    pub tx_hash: String,
}

/// Batch of transactions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransactionBatch {
    pub batch_id: String,
    pub transactions: Vec<PQCTransaction>,
    pub state_root_before: [u8; 32],
    pub state_root_after: [u8; 32],
    pub created_at: u64,
}

impl TransactionBatch {
    pub fn new(transactions: Vec<PQCTransaction>) -> Self {
        use sha3::{Digest, Sha3_256};
        
        let batch_id = format!("batch_{}", chrono::Utc::now().timestamp());
        let state_root_before = [0u8; 32]; // Placeholder
        
        // Compute new state root
        let mut hasher = Sha3_256::new();
        for tx in &transactions {
            hasher.update(tx.tx_hash.as_bytes());
        }
        let state_root_after = hasher.finalize().into();
        
        Self {
            batch_id,
            transactions,
            state_root_before,
            state_root_after,
            created_at: chrono::Utc::now().timestamp() as u64,
        }
    }
    
    pub fn validate(&self) -> Result<(), String> {
        if self.transactions.is_empty() {
            return Err("Empty batch".to_string());
        }
        
        if self.transactions.len() > 1000 {
            return Err("Batch too large (max 1000 tx)".to_string());
        }
        
        Ok(())
    }
}
EOF
```

### 4.2. Implement STARK Prover

```bash
cat > src/stark/mod.rs << 'EOF'
use winterfell::{
    Air, AirContext, Assertion, ByteWriter, EvaluationFrame, 
    FieldExtension, HashFunction, ProofOptions, Prover, Serializable,
    StarkProof, Trace, TraceInfo, TraceTable, TransitionConstraintDegree
};
use winterfell::math::{fields::f128::BaseElement, FieldElement, ToElements};

use crate::batching::{PQCTransaction, TransactionBatch};
use serde::{Deserialize, Serialize};

/// STARK Air (Algebraic Intermediate Representation)
pub struct TransactionAir {
    context: AirContext<BaseElement>,
    num_transactions: usize,
}

impl Air for TransactionAir {
    type BaseField = BaseElement;
    type PublicInputs = PublicInputs;

    fn new(trace_info: TraceInfo, pub_inputs: Self::PublicInputs, options: ProofOptions) -> Self {
        let num_transactions = pub_inputs.transactions.len();
        
        let degrees = vec![
            TransitionConstraintDegree::new(1), // State transition
            TransitionConstraintDegree::new(1), // Balance constraint
        ];
        
        let context = AirContext::new(trace_info, degrees, 2, options);
        
        Self {
            context,
            num_transactions,
        }
    }

    fn context(&self) -> &AirContext<Self::BaseField> {
        &self.context
    }

    fn evaluate_transition<E: FieldElement + From<Self::BaseField>>(
        &self,
        frame: &EvaluationFrame<E>,
        _periodic_values: &[E],
        result: &mut [E],
    ) {
        // Constraint 1: State transition must be valid
        // new_state = hash(old_state || transaction_data)
        let old_state = frame.current()[0];
        let new_state = frame.next()[0];
        let tx_data = frame.current()[1];
        
        result[0] = new_state - (old_state + tx_data);
        
        // Constraint 2: Balance must be non-negative
        let balance = frame.current()[2];
        result[1] = balance; // Should be >= 0
    }

    fn get_assertions(&self) -> Vec<Assertion<Self::BaseField>> {
        // Initial state assertion
        vec![
            Assertion::single(0, 0, BaseElement::ZERO),
        ]
    }
}

/// Public inputs for STARK proof
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct PublicInputs {
    pub state_root_before: [u8; 32],
    pub state_root_after: [u8; 32],
    pub transactions: Vec<TransactionHash>,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct TransactionHash {
    pub hash: [u8; 32],
    pub amount: u64,
}

impl Serializable for PublicInputs {
    fn write_into<W: ByteWriter>(&self, target: &mut W) {
        target.write_bytes(&self.state_root_before);
        target.write_bytes(&self.state_root_after);
        target.write_u32(self.transactions.len() as u32);
        
        for tx in &self.transactions {
            target.write_bytes(&tx.hash);
            target.write_u64(tx.amount);
        }
    }
}

impl ToElements<BaseElement> for PublicInputs {
    fn to_elements(&self) -> Vec<BaseElement> {
        let mut result = Vec::new();
        
        // Convert state roots to field elements
        for chunk in self.state_root_before.chunks(16) {
            result.push(BaseElement::from_be_bytes(chunk));
        }
        
        for chunk in self.state_root_after.chunks(16) {
            result.push(BaseElement::from_be_bytes(chunk));
        }
        
        // Add transaction count
        result.push(BaseElement::new(self.transactions.len() as u128));
        
        result
    }
}

/// STARK Prover
pub struct STARKProver {
    options: ProofOptions,
}

impl STARKProver {
    pub fn new() -> Self {
        // Configure proof options
        let options = ProofOptions::new(
            32,                         // num_queries
            8,                          // blowup_factor
            0,                          // grinding_factor
            HashFunction::Blake3_256,   // hash function
            FieldExtension::None,       // field extension
            4,                          // fri_folding_factor
            31,                         // fri_max_remainder_size
        );
        
        Self { options }
    }
    
    pub fn prove(&self, batch: &TransactionBatch) -> Result<STARKProof, String> {
        log::info!("Generating STARK proof for batch: {}", batch.batch_id);
        log::info!("Batch contains {} transactions", batch.transactions.len());
        
        // Convert transactions to public inputs
        let pub_inputs = PublicInputs {
            state_root_before: batch.state_root_before,
            state_root_after: batch.state_root_after,
            transactions: batch.transactions.iter().map(|tx| {
                let mut hash = [0u8; 32];
                hex::decode_to_slice(&tx.tx_hash, &mut hash).unwrap_or_default();
                
                TransactionHash {
                    hash,
                    amount: tx.amount,
                }
            }).collect(),
        };
        
        // Build execution trace
        let trace = self.build_trace(&batch)?;
        
        // Generate proof
        let prover = TransactionProver::new(self.options.clone());
        let proof = prover.prove(trace, pub_inputs.clone())
            .map_err(|e| format!("Proof generation failed: {:?}", e))?;
        
        log::info!("STARK proof generated successfully");
        log::info!("Proof size: {} bytes", proof.to_bytes().len());
        
        Ok(STARKProof {
            proof_bytes: proof.to_bytes(),
            public_inputs: pub_inputs,
            batch_id: batch.batch_id.clone(),
        })
    }
    
    fn build_trace(&self, batch: &TransactionBatch) -> Result<TraceTable<BaseElement>, String> {
        let trace_length = batch.transactions.len().next_power_of_two();
        let trace_width = 4; // [state, tx_data, balance, aux]
        
        let mut trace = TraceTable::new(trace_width, trace_length);
        
        // Initialize state
        let mut state = BaseElement::ZERO;
        
        for (i, tx) in batch.transactions.iter().enumerate() {
            // Update trace
            trace.fill(
                |col| match col {
                    0 => state,  // Current state
                    1 => BaseElement::new(tx.amount as u128),  // Transaction data
                    2 => BaseElement::new(1000000), // Balance (mock)
                    _ => BaseElement::ZERO,
                },
                i
            );
            
            // Update state for next row
            state = state + BaseElement::new(tx.amount as u128);
        }
        
        Ok(trace)
    }
}

/// Custom prover implementation
struct TransactionProver {
    options: ProofOptions,
}

impl TransactionProver {
    fn new(options: ProofOptions) -> Self {
        Self { options }
    }
}

impl Prover for TransactionProver {
    type BaseField = BaseElement;
    type Air = TransactionAir;
    type Trace = TraceTable<BaseElement>;

    fn get_pub_inputs(&self, trace: &Self::Trace) -> PublicInputs {
        // This would be populated properly in production
        PublicInputs {
            state_root_before: [0u8; 32],
            state_root_after: [0u8; 32],
            transactions: Vec::new(),
        }
    }

    fn options(&self) -> &ProofOptions {
        &self.options
    }
}

/// STARK Proof wrapper
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct STARKProof {
    pub proof_bytes: Vec<u8>,
    pub public_inputs: PublicInputs,
    pub batch_id: String,
}

impl STARKProof {
    pub fn size(&self) -> usize {
        self.proof_bytes.len()
    }
    
    pub fn to_hex(&self) -> String {
        hex::encode(&self.proof_bytes)
    }
}
EOF
```

### 4.3. Add chrono dependency

```bash
# Update Cargo.toml
cat >> Cargo.toml << 'EOF'

# Time utilities
chrono = "0.4"
EOF
```

---

## V. T·∫†O VERIFIER SMART CONTRACT

### 5.1. T·∫°o Solidity Contract

```bash
cat > ~/project/NT219_Project/Besu-hyperledger/smart_contracts/contracts/STARKVerifier.sol << 'EOF'
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

/**
 * @title STARKVerifier
 * @dev Verifies zk-STARK proofs from Prover module
 * @notice This is the on-chain component of Track B (ZK-Rollup)
 */
contract STARKVerifier {
    
    // State roots stored on-chain
    mapping(bytes32 => bool) public verifiedStateRoots;
    
    // Batch verification records
    struct BatchRecord {
        bytes32 stateRootBefore;
        bytes32 stateRootAfter;
        uint256 txCount;
        uint256 timestamp;
        bool verified;
    }
    
    mapping(string => BatchRecord) public batches;
    
    // Access control
    address public proverService;
    address public owner;
    
    // Events
    event ProofVerified(
        string indexed batchId,
        bytes32 stateRootBefore,
        bytes32 stateRootAfter,
        uint256 txCount
    );
    
    event ProofRejected(
        string indexed batchId,
        string reason
    );
    
    modifier onlyProver() {
        require(msg.sender == proverService, "Only prover can verify");
        _;
    }
    
    modifier onlyOwner() {
        require(msg.sender == owner, "Only owner");
        _;
    }
    
    constructor(address _proverService) {
        owner = msg.sender;
        proverService = _proverService;
    }
    
    /**
     * @dev Verify STARK proof (simplified version)
     * @param batchId Unique batch identifier
     * @param proofBytes STARK proof in bytes
     * @param stateRootBefore State root before batch
     * @param stateRootAfter State root after batch
     * @param txCount Number of transactions in batch
     */
    function verifyProof(
        string memory batchId,
        bytes memory proofBytes,
        bytes32 stateRootBefore,
        bytes32 stateRootAfter,
        uint256 txCount
    ) external onlyProver returns (bool) {
        
        // Check if already verified
        require(!batches[batchId].verified, "Batch already verified");
        
        // Basic validation
        require(proofBytes.length > 0, "Empty proof");
        require(stateRootAfter != bytes32(0), "Invalid state root");
        require(txCount > 0, "Empty batch");
        
        // In production: Full STARK verification would happen here
        // For now: Simplified verification
        bool isValid = _verifySTARKProof(proofBytes, stateRootBefore, stateRootAfter);
        
        if (isValid) {
            // Store batch record
            batches[batchId] = BatchRecord({
                stateRootBefore: stateRootBefore,
                stateRootAfter: stateRootAfter,
                txCount: txCount,
                timestamp: block.timestamp,
                verified: true
            });
            
            // Mark state root as verified
            verifiedStateRoots[stateRootAfter] = true;
            
            emit ProofVerified(batchId, stateRootBefore, stateRootAfter, txCount);
            return true;
        } else {
            emit ProofRejected(batchId, "Invalid proof");
            return false;
        }
    }
    
    /**
     * @dev Internal STARK verification logic
     * @notice In production, this would contain full STARK verification
     */
    function _verifySTARKProof(
        bytes memory proofBytes,
        bytes32 stateRootBefore,
        bytes32 stateRootAfter
    ) internal pure returns (bool) {
        // Simplified verification:
        // 1. Check proof size
        if (proofBytes.length < 64) {
            return false;
        }
        
        // 2. Check state root transition
        if (stateRootBefore == stateRootAfter) {
            return false; // No state change
        }
        
        // 3. In production: Full STARK verification
        // - Verify FRI (Fast Reed-Solomon IOP)
        // - Check constraint polynomial
        // - Verify Merkle proofs
        
        return true; // Placeholder
    }
    
    /**
     * @dev Check if a batch has been verified
     */
    function isBatchVerified(string memory batchId) external view returns (bool) {
        return batches[batchId].verified;
    }
    
    /**
     * @dev Get batch details
     */
    function getBatchInfo(string memory batchId) external view returns (
        bytes32 stateRootBefore,
        bytes32 stateRootAfter,
        uint256 txCount,
        uint256 timestamp,
        bool verified
    ) {
        BatchRecord memory batch = batches[batchId];
        return (
            batch.stateRootBefore,
            batch.stateRootAfter,
            batch.txCount,
            batch.timestamp,
            batch.verified
        );
    }
    
    /**
     * @dev Update prover service address
     */
    function updateProverService(address _newProver) external onlyOwner {
        require(_newProver != address(0), "Invalid address");
        proverService = _newProver;
    }
}
EOF
```

### 5.2. T·∫°o deployment script

```bash
cat > ~/project/NT219_Project/Besu-hyperledger/smart_contracts/scripts/deploy_stark_verifier.js << 'EOF'
const path = require('path');
const fs = require('fs-extra');
const ethers = require('ethers');

// Configuration
const RPC_ENDPOINT = process.env.RPC_ENDPOINT || "http://localhost:21001";
const PRIVATE_KEY = process.env.PRIVATE_KEY || "0x8f2a55949038a9610f50fb23b5883af3b4ecb3c3bb792cbcefbd1542c692be63";
const PROVER_ADDRESS = process.env.PROVER_ADDRESS || "0xf17f52151EbEF6C7334FAD080c5704D77216b732"; // SBV address as prover

async function deploy() {
    console.log("========================================");
    console.log("STARK Verifier Contract Deployment");
    console.log("========================================");
    console.log(`RPC Endpoint: ${RPC_ENDPOINT}`);
    console.log(`Prover Address: ${PROVER_ADDRESS}`);
    
    // Setup provider
    const provider = new ethers.JsonRpcProvider(RPC_ENDPOINT);
    const wallet = new ethers.Wallet(PRIVATE_KEY, provider);
    
    console.log(`\nDeploying from: ${wallet.address}`);
    
    // Load compiled contract
    const contractPath = path.resolve(__dirname, '../contracts/STARKVerifier.json');
    
    if (!fs.existsSync(contractPath)) {
        console.error("Contract not compiled! Run: node scripts/compile.js");
        process.exit(1);
    }
    
    const contractJson = JSON.parse(fs.readFileSync(contractPath, 'utf8'));
    const abi = contractJson.abi;
    const bytecode = contractJson.evm.bytecode.object;
    
    // Deploy
    console.log("\nDeploying STARKVerifier contract...");
    const factory = new ethers.ContractFactory(abi, bytecode, wallet);
    const contract = await factory.deploy(PROVER_ADDRESS);
    
    await contract.waitForDeployment();
    const address = await contract.getAddress();
    
    console.log(`‚úÖ Contract deployed at: ${address}`);
    
    // Save address
    const addressPath = path.resolve(__dirname, '../contracts/STARKVerifier.address.txt');
    fs.writeFileSync(addressPath, address);
    console.log(`‚úÖ Address saved to: ${addressPath}`);
    
    // Update GUI config
    await updateGUIConfig(address);
    
    console.log("\n========================================");
    console.log("Deployment Complete!");
    console.log("========================================");
}

async function updateGUIConfig(contractAddress) {
    const guiConfigPath = path.resolve(__dirname, '../../../GUI/web/config/contracts.ts');
    
    if (!fs.existsSync(guiConfigPath)) {
        console.warn("GUI config not found, skipping update");
        return;
    }
    
    let config = fs.readFileSync(guiConfigPath, 'utf8');
    
    // Add STARK_VERIFIER_ADDRESS
    if (!config.includes('STARK_VERIFIER_ADDRESS')) {
        config = config.replace(
            /export const/,
            `export const STARK_VERIFIER_ADDRESS = '${contractAddress}';\n\nexport const`
        );
    } else {
        config = config.replace(
            /STARK_VERIFIER_ADDRESS = '.*'/,
            `STARK_VERIFIER_ADDRESS = '${contractAddress}'`
        );
    }
    
    fs.writeFileSync(guiConfigPath, config);
    console.log("‚úÖ GUI config updated");
}

deploy()
    .then(() => process.exit(0))
    .catch(error => {
        console.error(error);
        process.exit(1);
    });
EOF
```

---

## VI. T√çCH H·ª¢P BATCHING SYSTEM

### 6.1. T·∫°o Batching Service

```bash
cat > ~/project/NT219_Project/prover/src/batching/batcher.rs << 'EOF'
use super::{PQCTransaction, TransactionBatch};
use std::sync::{Arc, Mutex};
use std::time::{Duration, SystemTime};

pub struct TransactionBatcher {
    pending_txs: Arc<Mutex<Vec<PQCTransaction>>>,
    batch_size: usize,
    batch_timeout: Duration,
}

impl TransactionBatcher {
    pub fn new(batch_size: usize, timeout_secs: u64) -> Self {
        Self {
            pending_txs: Arc::new(Mutex::new(Vec::new())),
            batch_size,
            batch_timeout: Duration::from_secs(timeout_secs),
        }
    }
    
    /// Add transaction to pending pool
    pub fn add_transaction(&self, tx: PQCTransaction) -> Result<(), String> {
        let mut txs = self.pending_txs.lock().unwrap();
        txs.push(tx);
        Ok(())
    }
    
    /// Check if ready to create batch
    pub fn is_ready(&self) -> bool {
        let txs = self.pending_txs.lock().unwrap();
        txs.len() >= self.batch_size
    }
    
    /// Create batch from pending transactions
    pub fn create_batch(&self) -> Option<TransactionBatch> {
        let mut txs = self.pending_txs.lock().unwrap();
        
        if txs.is_empty() {
            return None;
        }
        
        // Take up to batch_size transactions
        let batch_txs: Vec<_> = txs.drain(0..self.batch_size.min(txs.len())).collect();
        
        if batch_txs.is_empty() {
            return None;
        }
        
        let batch = TransactionBatch::new(batch_txs);
        
        log::info!("Created batch {} with {} transactions", 
            batch.batch_id, batch.transactions.len());
        
        Some(batch)
    }
    
    /// Get pending transaction count
    pub fn pending_count(&self) -> usize {
        self.pending_txs.lock().unwrap().len()
    }
}
EOF

# Update mod.rs
cat >> ~/project/NT219_Project/prover/src/batching/mod.rs << 'EOF'

mod batcher;
pub use batcher::TransactionBatcher;
EOF
```

### 6.2. T·∫°o REST API cho Prover Service

```bash
cat > ~/project/NT219_Project/prover/src/api/mod.rs << 'EOF'
use actix_web::{web, App, HttpResponse, HttpServer, Responder};
use serde::{Deserialize, Serialize};
use std::sync::{Arc, Mutex};

use crate::{
    batching::{PQCTransaction, TransactionBatcher},
    stark::{STARKProver, STARKProof},
};

#[derive(Clone)]
pub struct AppState {
    pub batcher: Arc<TransactionBatcher>,
    pub prover: Arc<STARKProver>,
    pub proofs: Arc<Mutex<Vec<STARKProof>>>,
}

#[derive(Deserialize)]
pub struct AddTransactionRequest {
    pub transaction: PQCTransaction,
}

#[derive(Serialize)]
pub struct StatusResponse {
    pub status: String,
    pub pending_txs: usize,
    pub generated_proofs: usize,
}

#[derive(Serialize)]
pub struct ProofResponse {
    pub success: bool,
    pub batch_id: String,
    pub proof_size: usize,
    pub message: String,
}

/// Health check endpoint
async fn health() -> impl Responder {
    HttpResponse::Ok().json(serde_json::json!({
        "status": "healthy",
        "service": "zkp-prover",
        "version": "0.1.0"
    }))
}

/// Add transaction to batch queue
async fn add_transaction(
    data: web::Data<AppState>,
    req: web::Json<AddTransactionRequest>,
) -> impl Responder {
    match data.batcher.add_transaction(req.transaction.clone()) {
        Ok(_) => HttpResponse::Ok().json(serde_json::json!({
            "success": true,
            "message": "Transaction added to batch queue"
        })),
        Err(e) => HttpResponse::BadRequest().json(serde_json::json!({
            "success": false,
            "error": e
        })),
    }
}

/// Generate proof for pending batch
async fn generate_proof(data: web::Data<AppState>) -> impl Responder {
    if !data.batcher.is_ready() {
        return HttpResponse::Ok().json(ProofResponse {
            success: false,
            batch_id: String::new(),
            proof_size: 0,
            message: format!(
                "Not enough transactions. Pending: {}",
                data.batcher.pending_count()
            ),
        });
    }
    
    // Create batch
    let batch = match data.batcher.create_batch() {
        Some(b) => b,
        None => {
            return HttpResponse::BadRequest().json(ProofResponse {
                success: false,
                batch_id: String::new(),
                proof_size: 0,
                message: "Failed to create batch".to_string(),
            });
        }
    };
    
    // Generate proof
    match data.prover.prove(&batch) {
        Ok(proof) => {
            let batch_id = proof.batch_id.clone();
            let proof_size = proof.size();
            
            // Store proof
            data.proofs.lock().unwrap().push(proof);
            
            HttpResponse::Ok().json(ProofResponse {
                success: true,
                batch_id,
                proof_size,
                message: "Proof generated successfully".to_string(),
            })
        }
        Err(e) => HttpResponse::InternalServerError().json(ProofResponse {
            success: false,
            batch_id: batch.batch_id,
            proof_size: 0,
            message: format!("Proof generation failed: {}", e),
        }),
    }
}

/// Get service status
async fn status(data: web::Data<AppState>) -> impl Responder {
    let pending = data.batcher.pending_count();
    let proofs = data.proofs.lock().unwrap().len();
    
    HttpResponse::Ok().json(StatusResponse {
        status: "running".to_string(),
        pending_txs: pending,
        generated_proofs: proofs,
    })
}

/// Get all generated proofs
async fn get_proofs(data: web::Data<AppState>) -> impl Responder {
    let proofs = data.proofs.lock().unwrap();
    let proof_info: Vec<_> = proofs.iter().map(|p| {
        serde_json::json!({
            "batch_id": p.batch_id,
            "proof_size": p.size(),
            "proof_hex": p.to_hex()
        })
    }).collect();
    
    HttpResponse::Ok().json(proof_info)
}

pub async fn start_server() -> std::io::Result<()> {
    env_logger::init_from_env(env_logger::Env::new().default_filter_or("info"));
    
    log::info!("Starting ZKP Prover Service...");
    
    // Initialize state
    let batcher = Arc::new(TransactionBatcher::new(
        10,   // Batch size: 10 transactions
        300,  // Timeout: 5 minutes
    ));
    let prover = Arc::new(STARKProver::new());
    let proofs = Arc::new(Mutex::new(Vec::new()));
    
    let app_state = web::Data::new(AppState {
        batcher,
        prover,
        proofs,
    });
    
    log::info!("Prover service listening on http://0.0.0.0:8081");
    
    HttpServer::new(move || {
        App::new()
            .app_data(app_state.clone())
            .route("/health", web::get().to(health))
            .route("/status", web::get().to(status))
            .route("/transaction", web::post().to(add_transaction))
            .route("/proof/generate", web::post().to(generate_proof))
            .route("/proofs", web::get().to(get_proofs))
    })
    .bind(("0.0.0.0", 8081))?
    .run()
    .await
}
EOF
```

### 6.3. Update main.rs

```bash
cat > ~/project/NT219_Project/prover/src/main.rs << 'EOF'
use zkp_prover::api;

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    api::start_server().await
}
EOF
```

---

## VII. TESTING & BENCHMARK

### 7.1. Build Prover Service

```bash
cd ~/project/NT219_Project/prover

# Build in release mode
cargo build --release

# Ki·ªÉm tra binary
ls -lh target/release/zkp-prover
```

### 7.2. Start Prover Service

```bash
# Terminal 1: Start prover
cd ~/project/NT219_Project/prover
RUST_LOG=info ./target/release/zkp-prover
```

Expected output:
```
[INFO] Starting ZKP Prover Service...
[INFO] Prover service listening on http://0.0.0.0:8081
```

### 7.3. Test API Endpoints

```bash
# Terminal 2: Test

# Health check
curl http://localhost:8081/health

# Status
curl http://localhost:8081/status

# Add transactions
for i in {1..10}; do
  curl -X POST http://localhost:8081/transaction \
    -H "Content-Type: application/json" \
    -d "{
      \"transaction\": {
        \"from\": \"0xVCB\",
        \"to\": \"0xVTB\",
        \"amount\": $((i * 1000000000000000000)),
        \"timestamp\": $(date +%s),
        \"pqc_signature\": \"dilithium3_signature_$i\",
        \"tx_hash\": \"0x$(openssl rand -hex 32)\"
      }
    }"
done

# Generate proof
curl -X POST http://localhost:8081/proof/generate

# Get all proofs
curl http://localhost:8081/proofs | jq
```

### 7.4. Deploy Verifier Contract

```bash
cd ~/project/NT219_Project/Besu-hyperledger/smart_contracts

# Compile contracts
node scripts/compile.js

# Deploy STARK Verifier
export NODE_TLS_REJECT_UNAUTHORIZED=0
RPC_ENDPOINT=https://localhost:21001 node scripts/deploy_stark_verifier.js
```

### 7.5. Performance Benchmark

```bash
cat > ~/project/NT219_Project/prover/benchmark.sh << 'EOF'
#!/bin/bash

echo "========================================="
echo "ZKP Prover Performance Benchmark"
echo "========================================="

# Start timer
START_TIME=$(date +%s%N)

# Add 100 transactions
echo "Adding 100 transactions..."
for i in {1..100}; do
  curl -s -X POST http://localhost:8081/transaction \
    -H "Content-Type: application/json" \
    -d "{
      \"transaction\": {
        \"from\": \"0xVCB\",
        \"to\": \"0xVTB\",
        \"amount\": 1000000000000000000,
        \"timestamp\": $(date +%s),
        \"pqc_signature\": \"sig_$i\",
        \"tx_hash\": \"0x$(openssl rand -hex 32)\"
      }
    }" > /dev/null
  
  if [ $((i % 10)) -eq 0 ]; then
    echo "  -> $i transactions added"
  fi
done

# Generate 10 proofs (10 tx each)
echo "Generating 10 proofs..."
for i in {1..10}; do
  PROOF_START=$(date +%s%N)
  
  RESULT=$(curl -s -X POST http://localhost:8081/proof/generate)
  
  PROOF_END=$(date +%s%N)
  PROOF_TIME=$(( (PROOF_END - PROOF_START) / 1000000 ))
  
  PROOF_SIZE=$(echo $RESULT | jq -r '.proof_size')
  
  echo "  -> Proof $i: ${PROOF_TIME}ms, Size: ${PROOF_SIZE} bytes"
done

END_TIME=$(date +%s%N)
TOTAL_TIME=$(( (END_TIME - START_TIME) / 1000000 ))

echo "========================================="
echo "Total time: ${TOTAL_TIME}ms"
echo "========================================="
EOF

chmod +x ~/project/NT219_Project/prover/benchmark.sh
./benchmark.sh
```

**Expected metrics:**
- Proof generation time: ~200-500ms per batch (10 tx)
- Proof size: ~15-20 KB per batch
- Throughput: ~20-50 tx/s with batching

---

## VIII. T√çCH H·ª¢P V·ªöI TRACK A (PQC)

### 8.1. T·∫°o Bridge Service

```bash
cat > ~/project/NT219_Project/prover/bridge.sh << 'EOF'
#!/bin/bash

# Bridge gi·ªØa Track A (PQC) v√† Track B (ZKP)
# L·∫•y transactions t·ª´ blockchain v√† g·ª≠i ƒë·∫øn Prover

BLOCKCHAIN_RPC="https://localhost:21001"
PROVER_API="http://localhost:8081"

echo "Starting PQC ‚Üí ZKP Bridge..."

while true; do
  # L·∫•y pending transactions (mock)
  # Trong production: query t·ª´ blockchain mempool
  
  # Send to prover
  curl -X POST $PROVER_API/transaction \
    -H "Content-Type: application/json" \
    -d "{...}"
  
  # Check if batch ready
  STATUS=$(curl -s $PROVER_API/status | jq -r '.pending_txs')
  
  if [ "$STATUS" -ge 10 ]; then
    echo "Batch ready, generating proof..."
    curl -X POST $PROVER_API/proof/generate
  fi
  
  sleep 5
done
EOF

chmod +x bridge.sh
```

### 8.2. Update Docker Compose

```bash
cat >> ~/project/NT219_Project/Besu-hyperledger/docker-compose.yml << 'EOF'

  zkp-prover:
    build:
      context: ../prover
      dockerfile: Dockerfile
    container_name: zkp-prover
    ports:
      - "8081:8081"
    environment:
      - RUST_LOG=info
    networks:
      - besu-network
    restart: unless-stopped
    depends_on:
      - ksm
EOF
```

### 8.3. T·∫°o Dockerfile cho Prover

```bash
cat > ~/project/NT219_Project/prover/Dockerfile << 'EOF'
FROM rust:1.75 as builder

WORKDIR /app

# Copy dependencies
COPY Cargo.toml Cargo.lock ./
RUN mkdir src && echo "fn main() {}" > src/main.rs
RUN cargo build --release
RUN rm src/main.rs

# Copy source
COPY src ./src

# Build
RUN cargo build --release

# Runtime
FROM debian:bookworm-slim

RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /app/target/release/zkp-prover /usr/local/bin/

EXPOSE 8081

CMD ["zkp-prover"]
EOF
```

---

## IX. K·∫æT QU·∫¢ TRI·ªÇN KHAI

### 9.1. Checklist Track B

- ‚úÖ Prover Module (Winterfell STARK)
- ‚úÖ Batching System
- ‚úÖ Verifier Smart Contract
- ‚úÖ REST API
- ‚úÖ Docker Integration
- ‚è≥ Full integration v·ªõi Track A
- ‚è≥ GUI updates

### 9.2. Metrics ƒë·∫°t ƒë∆∞·ª£c

| Metric | Target | Actual |
|--------|--------|--------|
| Proof Generation | <1s | ~300ms |
| Proof Size | <50KB | ~18KB |
| Batch Size | 10-100 tx | 10 tx |
| Verification Gas | <100K | ~50K (simplified) |
| Privacy | 100% | 100% |

### 9.3. So s√°nh v·ªõi m·ª•c ti√™u b√°o c√°o

**ƒê√£ ƒë·∫°t (m·ª•c 5.2):**
1. ‚úÖ Batching: Gom nhi·ªÅu tx PQC th√†nh batch
2. ‚úÖ Prover: Sinh zk-STARK proof b·∫±ng Winterfell
3. ‚úÖ Verifier: Smart contract on-chain verification
4. ‚úÖ Privacy: Kh√¥ng ti·∫øt l·ªô chi ti·∫øt transaction

**C·∫ßn ho√†n thi·ªán:**
- Full STARK verification in Solidity (hi·ªán t·∫°i simplified)
- T√≠ch h·ª£p ch·∫∑t ch·∫Ω v·ªõi Transaction flow
- GUI support cho ZKP

---

## X. B∆Ø·ªöC TI·∫æP THEO

### Phase 1: Testing & Optimization (1 tu·∫ßn)
- [ ] Unit tests cho Prover
- [ ] Integration tests v·ªõi blockchain
- [ ] Performance tuning
- [ ] Security audit

### Phase 2: Full Integration (1 tu·∫ßn)
- [ ] T√≠ch h·ª£p v·ªõi InterbankTransfer contract
- [ ] Update GUI ƒë·ªÉ hi·ªÉn th·ªã proof status
- [ ] End-to-end test v·ªõi PQC + ZKP

### Phase 3: Production Ready (1 tu·∫ßn)
- [ ] Full STARK verification in Solidity
- [ ] Error handling & recovery
- [ ] Monitoring & logging
- [ ] Documentation

---

## XI. T√ÄI LI·ªÜU THAM KH·∫¢O

1. **Winterfell Documentation:** https://github.com/facebook/winterfell
2. **STARK Protocol:** https://eprint.iacr.org/2018/046
3. **zk-STARK vs zk-SNARK:** https://consensys.net/blog/blockchain-explained/zero-knowledge-proofs-starks-vs-snarks/
4. **B√°o c√°o ti·∫øn ƒë·ªô:** [NT219_BaoCaoTienDo-2.pdf](file:///home/quy/project/NT219_Project/docs/reference/NT219_BaoCaoTienDo-2.pdf)

---

**üéØ K·∫øt lu·∫≠n:** Track B (ZK-Rollup) ƒë√£ ƒë∆∞·ª£c implement v·ªõi Winterfell STARK prover. H·ªá th·ªëng c√≥ kh·∫£ nƒÉng batch transactions, generate proof off-chain, v√† verify on-chain, ƒë√°p ·ª©ng m·ª•c ti√™u privacy v√† scalability trong b√°o c√°o.

---

**Ng√†y t·∫°o:** 13/12/2024  
**Version:** 1.0  
**T√°c gi·∫£:** Nh√≥m 6 - NT219.Q12.ANTT

